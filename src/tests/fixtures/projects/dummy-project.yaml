defaults:
    description: defaults for all projects in this file
    salt: '2016.3' # the version of salt these project use
    domain: example.org
    # addressing within VPC
    intdomain: example.internal
    # 'lax', 'metrics', 'gateway', etc
    subdomain: null
    # projects with an explicit `repo` attribute support branch deployments with
    # ./bldr deploy
    repo: null
    # repository containing build instructions for this project
    formula-repo: null
    # repo containing project pillar data (credentials typically)
    # only the master-server will have a copy of this and only the master-server
    # will need permissions to clone it
    private-repo: ssh://github.com/exampleorg/builder-private-example
    # default branch to use when creating new instances
    default-branch: master
    # 
    formula-dependencies:
        - https://github.com/example/builder-base-formula
    aws:
        ec2:
            cluster-size: 1
            dns-internal: False
            # nodes to temporarily delete, for later recreation
            # https://martinfowler.com/bliki/PhoenixServer.html
            suppressed: []
            overrides: {}
            # find more here: http://cloud-images.ubuntu.com/releases/
            ami: ami-9eaa1cf6  # Ubuntu 14.04
            master_ip: 10.0.2.42
        type: t2.small
        region: us-east-1
        vpc-id: vpc-78a2071d  # vpc-id + subnet-id are peculiar to AWS account + region
        subnet-id: subnet-1d4eb46a # elife-public-subnet
        subnet-cidr: '10.0.2.0/24'
        redundant-subnet-id: subnet-7a31dd46 # elife-public-subnet-2
        redundant-subnet-cidr: '10.0.2.0/24'
        rds:
            # rds defaults only used if an `rds` section present in project
            # explicit database name overrides the one generated at template creation
            name: <defined at generation>
            multi-az: false
            engine: postgres
            # ensure this matches the version of Postgres you install on server!
            version: '9.4'
            type: db.t2.small
            storage: 5 # GB
            backup-retention: 28 # days
            # two subnets are required in two different availability zones
            # http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbsubnet-group.html
            params: []
            subnets:
                # two are required
                - subnet-foo
                - subnet-bar
        ext:
            # ext defaults only used if an `ext` section present in project
            # external hdd
            size: 10 # GB
            device: /dev/sdh
        elb:
            # elb defaults only used if an 'elb' section present in project
            stickiness: false
            protocol: http
            additional_listeners: {}
            idle_timeout: 60
            certificate: arn:aws:iam::...:...
            healthcheck:
                protocol: http
                port: 80
                path: /ping
                timeout: 4 
                interval: 5
                unhealthy_threshold: 2
                healthy_threshold: 2
        sns: []
        sqs: []
        s3: []
        cloudfront:
            # cloudfront defaults only used if a 'cloudfront' section present in project
            subdomains-without-dns: []
            origins: {}
            certificate_id: 'dummy...'
            cookies: []
            compress: true
            headers: []
            errors: null
            default-ttl: 300 # seconds
            logging: false
        # TODO: maybe move this into a 'terraform'/'terraform-alt' key separate from 'aws' and 'aws-alt'
        fastly:
            # fastly defaults only used if a 'fastly' section present in project
            subdomains: []
            subdomains-without-dns: []
            dns:
                cname: something.fastly.net
            gcslogging: false
            healthcheck: false
            vcl: []
        subdomains: []
        elasticache:
            # elasticache defaults only used if an `rds` section present in project
            type: cache.t2.small
            engine: redis
            az: us-east-1a
            subnets:
                # TODO: are two required?
                - subnet-foo
                - subnet-bar
            version: "2.8.24"
            configuration:
                maxmemory-policy: volatile-ttl
            clusters: 1
    aws-alt:
        fresh:
            description: uses a plain Ubuntu basebox instead of an ami
            ec2:
                ami: ami-9eaa1cf6 # Ubuntu 14.04
    vagrant:
        box: ubuntu/trusty64 # Ubuntu 14.04
        box-url: null # not needed for boxes hosted on Atlas 
        ip: 192.168.33.44
        ram: 1024
        cpus: 2
        cpucap: 100 # percent (vagrant default)

# basic vagrant and aws, no alternative config
dummy1:
    # disabled so we can test subdomain-less projects
    #subdomain: dummy1 # dummy.elifesciences.org
    repo: ssh://git@github.com/elifesciences/dummy1
    aws:
        type: t2.micro
        ports:
            - 22
    vagrant:
        ports:
            1239: 80

# elaborate aws and vagrant, several alternate configs
dummy2:
    subdomain: dummy2 # dummy.elifesciences.org
    repo: ssh://git@github.com/elifesciences/dummy2
    meta:
        description: "foo"
    aws:
        ports:
            - 22
            - 80:
                guest: 80
                cidr-ip: 0.0.0.0/0
        ec2:
            ami: ami-111111
        rds:
            storage: 10
        subdomains:
            - official
    aws-alt:
        # uses an rds backend and different ami
        alt-config1:
            rds:
                storage: 15
                type: db.m4.huge
            ec2:
                ami: ami-22222
    vagrant:
        ports:
            1239: 80
    vagrant-alt:
        # a cut down instance
        alt-config1:
            ram: 256
            cpus: 1
            cpucap: 25

# basic aws, no vagrant, alternate aws configs
dummy3:
    subdomain: dummy3
    repo: ssh://git@github.com/elifesciences/dummy3
    meta:
        description: "foo"
    aws:
        ec2:
            ami: ami-111111
        ports:
            - 22
    aws-alt:
        # uses an rds backend, snapshot on delete
        alt-config1:
            ports:
                - 80
            rds:
                storage: 15
            ext:
                size: 200
        # uses an rds backend, no snapshot on delete
        alt-config2:
            rds:
                deletion-policy: Delete

just-some-sns:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ec2: false
        sns: 
            - widgets-{instance}

project-with-sqs:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ec2: false
        sqs: 
            project-with-sqs-incoming-{instance}: 
                subscriptions:
                    - widgets-{instance}

project-with-s3:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ec2: false
        s3: 
            widgets-{instance}: 
            widgets-archive-{instance}: 
                deletion-policy: retain
            widgets-static-hosting-{instance}:
                website-configuration:
                    index-document: index.html
                cors: true
            widgets-just-access-{instance}:
                public: true

project-with-ext:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ports:
            - 80
        ext: 
            size: 200

project-with-cloudfront:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: www
    aws:
        ports:
            - 80
        cloudfront:
            subdomains:
                - "{instance}--cdn-of-www"
                - ""
            subdomains-without-dns:
                - future
            cookies:
                - session_id
            headers:
                - Accept
            default-ttl: 5
            logging:
                bucket: acme-logs

project-with-cloudfront-minimal:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: www
    aws:
        ports:
            - 80
        cloudfront:
            subdomains:
                - "{instance}--cdn-of-www"

project-with-cloudfront-error-pages:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: www
    aws:
        ports:
            - 80
        cloudfront:
            subdomains:
                - "{instance}--cdn-of-www"
            errors: 
                domain: "{instance}--example-errors.com"
                pattern: "???.html"
                codes:
                    502: "/5xx.html"
                protocol: http

project-with-cloudfront-origins:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ports:
            - 80
        cloudfront:
            subdomains:
                - "{instance}--cdn"
            origins:
                default-bucket:
                    hostname: "{instance}--default-bucket.s3.amazonaws.com"
                some-bucket:
                    hostname: "{instance}--some-bucket.s3.amazonaws.com"
                    pattern: articles/*
                    headers:
                        - Referer
                    cookies:
                        - session_id

project-with-fastly-minimal:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: www
    aws:
        ports:
            - 80
        fastly:
            subdomains:
                - "{instance}--cdn-of-www"

project-with-fastly-complex:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: www
    aws:
        ports:
            - 80
        fastly:
            subdomains:
                - "{instance}--cdn1-of-www"
                - "{instance}--cdn2-of-www"
            subdomains-without-dns:
                - "future"
            healthcheck:
                path: /ping-fastly
            vcl:
                - "gzip-by-regex"

project-with-fastly-gcs:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: www
    aws:
        ports:
            - 80
        fastly:
            subdomains:
                - "{instance}--cdn-of-www"
            gcslogging:
                bucket: my-bucket
                path: my-project/
                period: 1800

project-with-cluster:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: project-with-cluster
    aws:
        ports:
            - 80
        ec2:
            cluster-size: 2
            dns-internal: True
        elb: 
            protocol: http
        subdomains:
            - project.tv
            - ""

project-with-cluster-suppressed:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: project-with-cluster
    # no internal domain, while the public 'domain' is true by default
    intdomain: false
    aws:
        ports:
            - 80
        ec2:
            cluster-size: 3
            suppressed: [1]
        ext:
            size: 10
        elb: 
            protocol: http

project-with-cluster-overrides:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: project-with-cluster
    # no internal domain, while the public 'domain' is true by default
    intdomain: false
    aws:
        ports:
            - 80
        ec2:
            cluster-size: 2
            overrides:
                1: 
                    ext: 
                        size: 20
        ext:
            size: 10
        elb: 
            protocol: http

project-with-stickiness:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: project-with-cluster
    # no internal domain, while the public 'domain' is true by default
    intdomain: false
    aws:
        ports:
            - 80
        ec2:
            cluster-size: 2
        elb: 
            protocol: http
            stickiness:
                type: cookie
                cookie-name: mysessionid

project-with-multiple-elb-listeners:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: project-with-cluster
    # no internal domain, while the public 'domain' is true by default
    intdomain: false
    aws:
        ports:
            - 80
            - 8001
        ec2:
            cluster-size: 2
        elb: 
            protocol: http
            additional_listeners:
                some_daemon:
                    protocol: https
                    port: 8001
        subdomains:
            - project.tv
            - ""

project-with-cluster-integration-tests:
    repo: ssh://git@github.com/elifesciences/dummy3
    subdomain: project-with-cluster
    # no dummy domains since we really create this on CloudFormation
    domain: false
    intdomain: false
    aws:
        ports:
            - 80
            - 22
        ec2:
            cluster-size: 2
        elb: 
            protocol: http
            healthcheck:
                protocol: tcp
                port: 22

project-with-db-params:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ports: [80]
        rds:
            params:
                key1: val1
                key2: val2

project-with-rds-only:
    repo: ssh://git@github.com/elifesciences/dummy3
    aws:
        ec2: false
        rds:
            storage: 5

project-with-elasticache-redis:
    domain: False
    intdomain: False
    subdomain: www
    aws:
        ec2: false
        ports:
            - 80
        elasticache:
            engine: redis

project-with-multiple-elasticaches:
    domain: False
    intdomain: False
    subdomain: www
    aws:
        ec2: false
        ports:
            - 80
        elasticache:
            engine: redis
            clusters: 3
            configuration:
                maxmemory-policy: volatile-lru
            suppressed: [3]
            overrides:
                2: 
                    type: cache.t2.medium
                    configuration:
                        maxmemory-policy: volatile-ttl

project-with-fully-overridden-elasticaches:
    domain: False
    intdomain: False
    subdomain: www
    aws:
        ec2: false
        ports:
            - 80
        elasticache:
            engine: redis
            clusters: 2
            configuration:
                maxmemory-policy: volatile-lru
            overrides:
                1:
                    configuration:
                        maxmemory-policy: volatile-ttl
                2: 
                    configuration:
                        maxmemory-policy: volatile-ttl
